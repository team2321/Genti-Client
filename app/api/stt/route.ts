import { NextResponse } from "next/server";
import * as sdk from "microsoft-cognitiveservices-speech-sdk";
/////////
import ffmpegInstaller from "ffmpeg-static";
/////////
import ffmpeg from "fluent-ffmpeg";
import fs from "fs/promises";
import path from "path";
import os from "os";

export const runtime = "nodejs";

/////////
// ğŸ‘‡ [ì¶”ê°€ 2] fluent-ffmpegì—ê²Œ "ì‹¤í–‰ íŒŒì¼ì€ ì—¬ê¸°ì— ìˆì–´!"ë¼ê³  ì•Œë ¤ì¤ë‹ˆë‹¤.
if (ffmpegInstaller) {
  ffmpeg.setFfmpegPath(ffmpegInstaller);
}



// Content Safety íƒ€ì… ì •ì˜
type Category = "Hate" | "SelfHarm" | "Sexual" | "Violence";

interface AnalysisResult {
  category: Category;
  severity: number;
}

interface SafetyResponse {
  blocklistsMatch: any[];
  categoriesAnalysis: AnalysisResult[];
  error?: { code: string; message: string };
}
/////////



// API Handler
export async function POST(req: Request) {
  let tempInputPath: string | null = null;
  let tempOutputPath: string | null = null;

  try {
    const form = await req.formData();
    const file = form.get("file") as File;

    if (!file) {
      return NextResponse.json({ error: "No file provided" }, { status: 400 });
    }

    // ì„ì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±
    const tempDir = os.tmpdir();
    const randomId = Math.random().toString(36).substring(7);
    tempInputPath = path.join(tempDir, `input_${randomId}.webm`);
    tempOutputPath = path.join(tempDir, `output_${randomId}.wav`);

    // WebM íŒŒì¼ì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    const arrayBuffer = await file.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    await fs.writeFile(tempInputPath, buffer);

    // FFmpegë¡œ ë³€í™˜ (Promiseë¡œ ë˜í•‘)
    await new Promise((resolve, reject) => {
      ffmpeg(tempInputPath!)
        .outputOptions(["-acodec pcm_s16le", "-ac 1", "-ar 16000"])
        .output(tempOutputPath!)
        .on("end", resolve)
        .on("error", reject)
        .run();
    });

    // ë³€í™˜ëœ WAV íŒŒì¼ ì½ê¸°
    const wavBuffer = await fs.readFile(tempOutputPath);

    // Azure Speech ì„¤ì •
    const speechConfig = sdk.SpeechConfig.fromSubscription(
      process.env.AZURE_SPEECH_KEY!,
      process.env.AZURE_SPEECH_REGION!
    );
    speechConfig.speechRecognitionLanguage = "ko-KR"; // í•œêµ­ì–´ ì„¤ì •

    // WAV ë²„í¼ë¥¼ Azure Speech SDKì— ì „ë‹¬
    const audioConfig = sdk.AudioConfig.fromWavFileInput(wavBuffer);
    const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);

    // ìŒì„± ì¸ì‹ ì‹¤í–‰
    const result = await new Promise<sdk.SpeechRecognitionResult>(
      (resolve, reject) => {
        recognizer.recognizeOnceAsync(
          (result) => {
            recognizer.close();
            resolve(result);
          },
          (error) => {
            recognizer.close();
            reject(error);
          }
        );
      }
    );

    // ê²°ê³¼ í™•ì¸ ë° ë°˜í™˜
    if (result.reason === sdk.ResultReason.RecognizedSpeech) {
      console.log("Recognition successful:", result.text);


      /////////
      // ============================================================
      // ğŸš€ [í†µí•© ë¶€ë¶„] ì—¬ê¸°ì„œ Content Safety APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
      // Python ì½”ë“œì˜ requests.post ë¡œì§ì„ fetchë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.
      // ============================================================
      
      const safetyEndpoint = process.env.AZURE_CONTENT_SAFETY_ENDPOINT!;
      const safetyKey = process.env.AZURE_CONTENT_SAFETY_KEY!;
      const apiVersion = "2024-09-01";
      
      const safetyUrl = `${safetyEndpoint}/contentsafety/text:analyze?api-version=${apiVersion}`;

      const safetyResponse = await fetch(safetyUrl, {
        method: "POST",
        headers: {
          "Ocp-Apim-Subscription-Key": safetyKey,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          // text: recognizedText, // STT ê²°ê³¼ê°€ ì—¬ê¸°ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤!
          text: result.text, // STT ê²°ê³¼ê°€ ì—¬ê¸°ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤!
          blocklistNames: [],
        }),
      });

      if (!safetyResponse.ok) {
        throw new Error(`Content Safety API Error: ${safetyResponse.statusText}`);
      }

      const safetyResult: SafetyResponse = await safetyResponse.json();

      // [ì‹¬íŒ ë¡œì§] Pythonì˜ make_decision í•¨ìˆ˜ ë¡œì§ êµ¬í˜„
      const rejectThresholds: Record<Category, number> = {
        Hate: 4,
        SelfHarm: 4,
        Sexual: 4,
        Violence: 4,
      };

      let finalAction = "Accept";
      const actionDetails: Record<string, string> = {};

      // ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ í™•ì¸
      if (safetyResult.categoriesAnalysis) {
        for (const analysis of safetyResult.categoriesAnalysis) {
          const category = analysis.category;
          const severity = analysis.severity;
          const threshold = rejectThresholds[category];

          let action = "Accept";
          // ê¸°ì¤€ì¹˜ ì´ìƒì´ë©´ Reject
          if (threshold !== -1 && severity >= threshold) {
            action = "Reject";
            finalAction = "Reject";
          }
          actionDetails[category] = action;
        }
      }

      // ìµœì¢… ì‘ë‹µ ë°˜í™˜
      return NextResponse.json({
        // text: recognizedText,
        text: result.text,
        safetyDecision: finalAction, // "Accept" ë˜ëŠ” "Reject"
        safetyDetails: actionDetails, // ê° í•­ëª©ë³„ ê²°ê³¼
        rawSafetyResult: safetyResult // (ë””ë²„ê¹…ìš©) ì›ë³¸ ë°ì´í„°
      });
      /////////



      // return NextResponse.json({ text: result.text });
    } else if (result.reason === sdk.ResultReason.NoMatch) {
      console.log("No speech could be recognized");
      return NextResponse.json({ text: "", error: "No speech recognized" });
    } else if (result.reason === sdk.ResultReason.Canceled) {
      const cancellation = sdk.CancellationDetails.fromResult(result);
      console.error("Recognition canceled:", cancellation.reason);
      return NextResponse.json(
        {
          text: "",
          error: `Recognition canceled: ${cancellation.reason}`,
        },
        { status: 500 }
      );
    }

    return NextResponse.json({ text: "" });
  } catch (error) {
    console.error("Error in speech recognition:", error);
    return NextResponse.json(
      {
        error: "Failed to process audio",
        details: error instanceof Error ? error.message : "Unknown error",
      },
      { status: 500 }
    );
  } finally {
    // ì„ì‹œ íŒŒì¼ ì‚­ì œ
    if (tempInputPath) {
      await fs.unlink(tempInputPath).catch(console.error);
    }
    if (tempOutputPath) {
      await fs.unlink(tempOutputPath).catch(console.error);
    }
  }
}
